占楼更新。常见问题 FAQ  
  
1，影响Lora效果的因素有哪些，为什么我做的效果不理想，或者出现构图错误？  
  
影响Lora效果的因素很多，训练中最重要的是素材质量。像我上面那些从小红书上扒下来的垃圾，怎么练也不可能练好。你要训练服装、鞋子这些，必须有高清素材源。  
  
素材质量中最重要的是分辨率。下面简单说以下分辨率：  
  
受显存影响，训练时分辨率不是无限大的。你的显卡越好，分辨率就可以越大，练出的效果就越好。从这个角度说，越贵的显卡练出的丹越好(在图片质量保证的前提下)  
  
假设你有图片尺寸是 1080，1920，在A100上就可以直接用这个尺寸练，练出来的出图出768，1024无压力。假设你有高清图，还是去租A100来练吧。  
  
下面假设家用显卡能允许 512,768(这是我的8G显存)分辨率的图片，那么无论原图多大，最后都会被处理成512,768，也就是说图片在压缩过程中会损失。  
  
这样你练出来的丹，分辨率其实就是512，768的。 但是你出图不可能出512,768的图，所以你实际上“拉伸”了你的模型。  
  
  
当然对于机器而言，SD是随机填充色块，不存在“拉伸”的问题，但是分辨率大还是要求更多细节，而你模型分辨率小，提供不了这么多细节，结果就是随机填充进去的随机的内容，占据了这些空间，所以怎么看都不像。  
  
这个问题随着你要求画面幅度越大越严重，最后可能导致构图错误。因为你训练用的小图，让它出大图，会有一些空间没被“映射”(实际上不是映射的关系)出来，所以会产生一些随机的，无法理解的内容。  
  
所以，一换显卡，二换高清图。  
  
  
2，与素材的构图不匹配  
  
Lora的工作原理是覆盖底模的相同prompt对应的元素，实现对底模内容的替换。构图显然也必须一致，不然你怎么替换呢？  
  
假设你有从什么女神、 前女友 之类的朋友圈里扒来的惨兮兮的几十张自拍，怎么可能指望还原出全身高清图？ 必然是半身还原半身，大头还原大头。  
  
假设训练集30张图片，29张是半身，还有一张模模糊糊的全身，这种情况下你训练完了以后强行要 full body, 结果肯定出来垃圾。  
  
正确的办法就是半身就半身，不要full body, standing, full view 这些，顺其自然。  
  
头部切下来也没用，半身的图片里面头部占的比例与全身的头部占的比例是不一样的，AI强行把半身的头部比例放到全身图里，结果还是错误的。  
  
3，三次元中正则(Reg)的实际工作模式  
  
  
First, there is LoRA applied to Dreambooth. The idea is to use prior-preservation class images to regularize the training process, and use low-occuring tokens. This will keep the model's generalization capability while keeping high fidelity. If you turn off prior preservation, and train text encoder embedding as well, it will become naive fine tuning.  
  
与二次元不同的是，三次元局部修改，需要关于“局部在整体的位置”这一先验信息。  
  
举例：  
  
![](https://img.nga.178.com/attachments/mon_202303/26/-9lddQ18h-7j7gK29T3cSk1-pm.jpg)  
  
假设 高亮框中的头部为我们需要训练的内容。现在裁剪下来这部分，机器学会后，请问头部应该放在哪里？——如果再要让它出全身图，这个头部机器会不知道该放在哪里(AI并不知道什么叫人)。  
  
我们现在把整张图作为reg输入，这样整张图与头部(框中的内容)的差异部分就是除了头部之外的部分，这部分包含了头部与身体之间位置关系的信息。  
  
模型作画时，就不会把头部(框中)放在框外的差异部分，也就是不会把头放在头不该在的地方了。  
  
具体来说，绘制头部时，首先读取Lora内的特征(而不是底模中的特征)，绘制出符合要求的头部。  
  
然后，头部的位置不会出现在框线外的reg掉的部分。  
  
但是你的prompt又要求输出1girl，1girl必须有身体，所以等效于该Lora模型中，找不到身体的信息，于是AI会自动回落到底模，从底模中取身体。  
  
这样就实现了Lora中的头部+底模中的身体。  
  
同时，由于Reg训练使得Lora中的头部不能与身体重合，因此在与底模中的身体配合，寻找相对位置时，会自动排除那些会导致头部与身体重合的随机解。  
  
这样就很好的融合了。  
  
为什么不能用其他人的身体？  
  
  
先说为什么不能，再说怎么实现：  
  
因为其他人的头部与训练集头部不同，Reg训练时“整张图”都是差异，所以机器又不知道该把训练集中的头放在哪里了…  
  
如果你能解决比例失调的问题，可以考虑把训练集中的头部移植到其他人的身体上，再来reg它，也许是可行的。  
  
https://bbs.nga.cn/read.php?&tid=35774713&pid=680427633&to=1