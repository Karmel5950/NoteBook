玩SD有一段时间了，目前AI绘图还是一个新兴产业，很多前沿性的内容还是很少资料。我经过一段时间自我探索，也参考各类论坛或网站的内容，目前对Lora也有了初步了解。  
之前看到论坛上一些其他帖子比如 “ lora训练的一些经验：衣服、脸部、正则化(regularization)等” [[https://bbs.nga.cn/read.php?tid=35591424](https://bbs.nga.cn/read.php?tid=35591424)] 有一定启发，但是也有很多错误的地方，比如说其实不需要抠图、不需要去头部… 适当的方法能够极大的简化Lora的训练，同时提高使用的泛用性。  
  
真正实现Lora三次元图片的“幻化”式换装，像在游戏里一样更换衣服， 把SD玩成美少女养成游戏  
  
  
//更新面部模型等，应用新方法，不再使用旧方法。  
  
1, SD的工作原理  
2，LoRA 是什么，我们用LoRA时发生了什么  
3，自由组合使用部分特征的Lora，如脸、服装、鞋子等  
4，训练集准备、TAG  
5，Regular 方法  
6，多个LoRA共同使用(细节程度、最小权重等)  
7，面部模型和其他模型的制作等 [[https://bbs.nga.cn/read.php?tid=35865472](https://bbs.nga.cn/read.php?tid=35865472)]  
8，使用XYZ图表应用多个lora出图  
9，正确使用提示词和tag提高效果  
(已经过时)  
9，prompt engineering 与人工标注有效降低模型的权重要求，减轻模糊和错位 [[https://bbs.nga.cn/read.php?tid=35850123](https://bbs.nga.cn/read.php?tid=35850123)]  
10，control net直出高清大图，缓解脸部失调  
  
  
  
我发现各种群或者论坛上大部分问题还是由于没有理论基础造成的。也就是不知道AI的工作原理。所以完全不讲原理也不行。  
  
  
以下均要求训练和使用Lora时，都使用 ChilloutMix底模、三次元模式。二次元的机制不太一样，不能混在一起说。  
  
1, SD的工作原理  
我知道原理没人爱看，但其实后面生成复杂的图都需要了解原理。你可能需要自学有关机器学习的内容，但是… 我知道这太难了(  
  

− 原理 ...

机器学习、GD这些都不讲了，太深了，只说说最简单的与SD有关的：  
  
先说机器在模型里都学的啥，再说怎么画的。  
  
最简单的是人脸识别。机器为什么能识别脸，因为它之前用图片训练过。你给机器一张图片，让机器寻找图片中脸部的“特征”，(此特征不是你理解的特征，是数学上的，后面不解释了)——  
  
然后让机器再看你自己，机器会对比你现在的脸部的“特征”与之前学习过的“特征”之间在数学上的差异。 假设认为差异小于1%就是本人，那么只要它认定你和之前图片里提取的特征值差异小于1%，就认为是你了。  
  
而让机器画一张脸，则是一个更复杂一些的工作。机器实际上不能根据“特征”来创作脸，只能根据特征来“筛选”脸。  
  
具体来说，SD绘画过程中先是随机创建色彩，然后与特征进行比较，选择最接近的方案，在这个基础上再次添加随机内容… 以此类推，迭代N次后的结果被认为与模型中的特征差异“足够小”，AI就认为画完了。  
  
让AI画一张脸，其实就是AI产生无数张随机脸，对比模型中的脸部特征值，找出差异最小的，在这个差异最小的基础上再修正，再产生无数张，再找差异最小的…… 最终形成一张与模型特征差异最小的脸部。  
  
接下来说tag和prompt word的原理  
  
那么一个人除了面部，还有很多部分。控制图中的元素也是按照这个方法。训练底模时，用tag表示不同的物体(的特征值)，假设我们使用5个tag，分别代表5个不同的物体的特征，那么在绘制过程中，通过输入5个prompt来对应这5个tag，AI会随机生成内容后，同时要求内容必须含有这5个tag对应的特征值。  
  
举例，假设人物除了面部之外还要求有衣服、鞋子、丝袜这些，那么这些对应位置随机产生的内容，也必须符合模型中关于“衣服、鞋子、丝袜”的特征，AI会不断在这些位置也产生随机内容并筛选符合要求的。  
  
最终，一幅图理想情况下是符合所有的prompt words。但是实际上不可能，往往你符合了A，图片就不符合B。  
  
这时候要引入权重，就是到底“多像” 算像？ 在SD里面，越靠前的prompt权重越高，靠后的权重会下降，AI会优先满足靠前的prompt，靠后的不一定会被满足。你可以通过()或者 prompt:2.0 来人为指定权重。  
  
  
  
  
  

  
  
  
2，LoRA 是什么，我们用LoRA时发生了什么  
  

− 原理 ...

  
loRa 是微调模型，原理比较复杂，你可以理解成“附加模型”。  
  
回到1，SD的绘画过程是寻找并筛选出符合所有prompt代表元素的特征值的随机内容。我们假设没有附加lora时，绘画的所要求的特征值就是底模中的特征值(比如韩国脸之类的)。  
  
复习以下流程：  
  
训练模型——模型(比如Chilloutmix)习得对应的特征(比如脸部)。  
  
SD产生随机脸部——与底模中的特征比较——找出差异最小的，并在此基础上再次随机化——与底模中的特征比较——找出差异最小的，并在此基础上再次随机化…… 循环若干次(Step就是次数)后，得到一个AI认为与底模中脸部特征差异最小的脸部，完成。  
  
我们想要AI产生指定的脸部，Lora就是替换底模中关于脸部的特征值。  
  
先通过图片训练Lora(实际上，让Lora具备了脸部识别的能力，但只能识别这张脸)，然后：  
  
SD产生随机脸部——与lora中的特征比较——找出差异最小的，并在此基础上再次随机化——与lora中的特征比较——找出差异最小的，并在此基础上再次随机化…… 循环若干次(Step就是次数)后，得到一个AI认为与lora中脸部特征差异最小的脸部，完成。  
  
差异最小，到底有多小？ 由权重控制。权重是一个相对值，0.5比0.4“更像” Lora里的特征，但不代表0.5比0.4更适合。因为更像Lora里的脸部，也许会导致其他部分更不像底模中的元素，整体就会扭曲出错。  
  
调节权重，就是找到一个最优解，使得产出的图片在与Lora的特征最接近的同时，也与底模中的其他内容最接近。  
  
衣服等同理，就是先用衣服图片训练Lora识别这件衣服。然后机器随机产生衣服，与Lora对比，寻找差异最小化的。  

  
  
3，自由组合使用部分特征的Lora，如脸、服装、鞋子等  
  
  
先写这一部分，这一部分也是最重要的。我们的目标就是实现一件衣服一个Lora，像在WOW里幻化一样随便更换三次元人物的服装。  
  
这里需要上一节的基础知识，但先写教程了：  
  
既然明确了Lora的规则，那么我们就要使SD在绘图时，在寻找指定的prompt时，优先在我们的Lora里寻找，而我们的Lora里刚好有符合prompt要求的特征，于是SD就会先按照Lora里描述的特征进行随机填充。在一定的权重下，SD绘图输出会更接近Lora里的特征(也就是你所训练的内容)。  
  
如果SD无法在Lora中寻找到合理的内容，则会回到底模(比如Chilloutmix)中寻找最接近prompt的特征值进行绘制。  
  
所以，我们的工作就是让自己训练的Lora尽可能符合你输入的prompt，是Lora中的特征覆盖掉底模的特征。如果Lora的特征描绘了人物身体的一部分，人物身体的这部分就会按照Lora的要求绘制，如果这部分穿了特定的衣服，就实现了Lora换装( 如果不穿衣服 )。  
  
  
其实计算机并不知道什么叫“衣服”。在你输入“1girl”后，当计算机绘制到身体部分时，如果你没有给出任何prompt words，那么计算机就会在底模里随便找个符合“1girl”的身体(只要不是男性的身体都可以)。如果我们要求计算机给我们一个JK妹子，那么我们输入的 “school uniform” 意思是身体部分必须符合 “school uniform” tag所代表的特征。如果底模里面有其他的制服，那么机器就会随机挑一件。如果底模里面没有，则会随机给出别的东西。也就是说，机器其实是在身体的位置上填入最接近 “school uniform” 要求的，且模型里面有的东西。  
  
假设我们要做一个Lora来表达一个特定的JK制服，AI怎么认为呢？  
  
AI首先发现，身体部分必须符合 “school uniform” tag所代表的特征。假设底模中和Lora中都含有该tag所代表的特征，那么根据Lora的权重值来决定是否要“更接近”Lora里面的这组标签的特征。假设权重值合理，AI就会随机绘画一个符合lora内部关于“school uniform” tag所代表的特征的色块，这个就是你要的制服了。。。 显然，权重越高，与Lora内“school uniform” tag所代表的特征越接近，但同时变化和创意也就越少，会变得完全和模型材料一致。而权重过低，则AI可能会不能完全表达lora中的这些特征，或者转而表达底模中的该特征了。  
  
  
接下来实践一个普通服装的Lora  
  
服装为电商平台上随机选择的，但是要求最好有全身照片(原因下面叙述)。所以我去某社交平台上爬了一些博主的图片：  
  
  
![](https://img.nga.178.com/attachments/mon_202303/25/-9lddQ18h-abwdZjT3cSsg-gx.jpg)  
  
这些图片可以看到质量较低，如果能找到高质量的图片当然最好了！ 但是也不必太过要求，因为我的显卡只能允许512*768分辨率，高于这个也会被压缩到这个值，所以只要比这个值高就可以了。你们可以根据你们显卡的规格来决定选用图片的尺寸。  
  
4，训练集准备、TAG  
  
经过实际测试、不需要抠图、不需要去头，几乎不需要做任何处理，唯一要做的是确定尺寸比例。  
  

− 处理训练集图片过程 ...

  
比如我已经确定了 512,768 这个尺寸了。然后在图像编辑器里设置裁剪，比例为512:768，固定(Fixed)。我用的GIMP，PS可以参照执行。  
  
剪切出第一张图，符合512:768的比例(具体是什么数值没有影响，一会统一改)，这张图要尽可能全身，如果不是全身，尽可能覆盖到人物的大多数位置。这张图将用于Regular方法。  
  
![](https://img.nga.178.com/attachments/mon_202303/25/-9lddQ18h-ih5pZaT3cSsg-i2.jpg)  
  
保存在一个目录中，比如叫 reg/1.jpg  
  
取消刚才的裁剪，重新再裁剪一张图(比例不变)，这次尽可能只裁剪到服装，尽可能覆盖完整的服装，但尽可能少覆盖到其他内容。  
  
![](https://img.nga.178.com/attachments/mon_202303/25/-9lddQ18h-iictK29T3cSsg-gn.jpg.medium.jpg)  
  
保存在另一个目录中，比如叫 train/1.jpg  
  
以此类推，这样一组图片就分成了两个目录，内容分别是：人物穿着这件衣服/这件衣服本身。   
  
最好有20张以上的不同图片，不同角度最好。因为是训练服装，所以也不要求是同一个人穿着。  
  
然后开始处理训练集。把 train 目录下的图片(也就是仅有衣服，不含其他)——导入Webui的训练集处理工具，尺寸选择“512，768”，下面选择“自动调整尺寸”。 由于我们的图片都是按照 512:768处理的，无论实际大小如何，经过自动调整后都会变成512，768的尺寸且不会有变形。  
  
  
![](https://img.nga.178.com/attachments/mon_202303/25/-9lddQ18h-ii62ZfT3cSs4-tx.jpg)  
  
打标可以选择 deepdooru，也可以选择BLIP，实际测试差异不大，选择deepbooru，允许插入一个自己的关键词，如果使用多个Lora(如3个以上) 会有一点用。  
  
经过实际测试，如果选择deepbooru tag模式，衣服是不需要删除tag的！ 如果衣服裁剪得好，基本上不太可能有任何多余的信息。最多用Boorudatasettagmanager加一个你自己的tag，比如说"mytag"。  
  
这样你就得到了一个打好标记的训练集，假设叫 10_testdress，并且加了一个自定义的标签叫 “testdress”。  

  
  
  
接下来同样处理 Regular Set(中文叫正则，可能有点误会，我下面解释)。 Regular Set 就是刚才那些按同样比例剪裁，但尽可能包含人物的图片。同样用批量处理成512，768的大小，但是不需要打tag(你打了，也不会有效果)。  
  
假设这个 Regular Set 叫做 5_testdress ，其中图片数量大于等于训练集图片数量。我建议最好直接一一对应，就是只有衣服/有全身 这么一个对应关系。  
  
5，Regular 方法  
  
NGA的那个帖子里面引述的关于reg的内容基本正确，其中引用的文献 [[https://blog.csdn.net/weixin_42468475/article/details/121755914](https://blog.csdn.net/weixin_42468475/article/details/121755914)] 大概是这个意思把，但是这里也没必要讲原理，一会再补。  
  

− Regularization的原理 ...

翻译成正则化确实有些误导。 其实这里Regularization就是告诉AI，这个元素(也就是你训练的脸啊，衣服啊)应该出现在图片的哪个相对位置。类似于上面文献中关于定位猫头鹰头部一样。  
  
但是机器无法正确理解“正确的位置”，所以你需要进行regular，也就是训练集会排除Regular集里有的、训练集里没有的东西——如果训练集的图片是一件衣服的话，被排除的自然是“除衣服之外的部分”。这样AI就学会了这件衣服不应该出现在这些部分，也就学会了这件衣服大概应该在人体的哪个位置了。  
  
同理，同一个人的脸部与全身照进行reg，也可以教会机器把这张脸放在(相对)哪里，这样就可以实现换脸了。  
  
与二次元不同，二次元的reg是reg掉“不符合训练集画风”的东西。一张不符合训练集画风的图片，自然会被全部否决掉，这样机器就知道不该生成什么样画风的图片了。  
  
而我们是要机器知道还是要生成带有这件衣服图案的身体，但是别生成到奇怪的地方去。那么“这件衣服之外的部分“和”衣服本身“通过reg来对比训练后，模型就会知道衣服哪里不该去了。  

  
  
开始训练：  
  
训练集  
  
/train/myset/10_testdress  
  
假设20张图片，仅包含服装部分的最小区域。  
  
Regular Set  
  
train/reg/5_testdress  
  
假设同样的20张图片，包含最大化的关于人物如何穿着该服装的信息。  
  
接下来就是训练了。别忘了训练时指定reg的位置，如$reg_data_dir = "./train/reg"  
  
我建议训练不少于5000步。 假设20张图，不考虑reg的情况下，次数可以设置为20(20_testdress)，epoch为10，batch假设是1，那么就是4000步，这已经是最少的要求了。reg其实也算一定的步数，这样加起来就是6000步，差不多了。  
  
假设训练成功了，我们得到了Lora testdress.safetensor ，下面怎么穿在人物身上呢？  
  
6，多个LoRA共同使用(细节程度、最小权重等)  
  
先尝试最简单的，让底模里的标准人穿上这件衣服。很多人会说什么权重要设置为0.6或者多少呀。其实权重值是调节AI生成产品”到底多像“Lora内的元素的。如果我们有多个Lora同时运作，那么就要精细调节每一个Lora的权重，最佳值可能不是0.6。  
  
原则上说，权重值越小越好，能用小的权重如果能表达出你要的效果，就避免了用更大的权重带来的一些副作用。这个需要上面的关于SD原理的知识，这里也先不说了。总之，如果多个Lora同时使用，为了尽可能减少互相干扰，我们应该追求用最小的权重达到目的。  
  
使用XYZ图表来进行测试，实验对于这个Lora( testdress.safetensor )不同权重下，相同prompt words的效果：  
  
  
![](https://img.nga.178.com/attachments/mon_202303/25/-9lddQ18h-d3hjZoT3cSsg-ec.jpg.medium.jpg)  
  
![](https://img.nga.178.com/attachments/mon_202303/25/-9lddQ18h-ekrtZpT3cSsg-ec.jpg.medium.jpg)  
  
可以发现其实0.2-0.3左右就能显现出服装大部分特征，随着权重值增大，特征也不断逼近真实(真实的肩带和腰带是黑色的，测试到0.5左右才完全显示出来)，但同时也对构图产生了影响。  
  
所以我们需要根据实际需要，找出合适的权重值。  
  
值得一提的是，多个Lora之间还会互相影响，实际上对于每一个随机种子来说，Lora最合适的权重值都不一样！。在使用多个Lora的条件下，往往是找到一张较好的构图后，通过XYZ图表反复微调各个Lora的权重组合，才能找到一个比较合理的平衡。因此让每一个Lora用最小的权重就能实现你要的细节程度，才可能最小的干扰其他Lora，否则每个Lora权重调得都很大也没用。  
  
下面假设有一个已经训练好的脸部，实现指定脸部+服装  
  
上面的权重值是服装的权重值，脸部模块的权重已经确定了。 可以看到对于同一个脸部，随着衣服的权重增大，图片细节也有少许变动。  
  
这就实现了指定的脸部模块+衣服  
  
![](https://img.nga.178.com/attachments/mon_202303/25/-9lddQ18h-33akZnT3cSsg-ec.jpg.medium.jpg)  
  
下面换一件衣服，脸部不变：  
  
![](https://img.nga.178.com/attachments/mon_202303/25/-9lddQ18h-ebz6ZgT3cSsg-ec.jpg.medium.jpg)  
  
可以明显看出，随着衣服权重的增加，衣服逐渐显现出颜色。低权重时颜色没有生效。这也表明了Lora的工作原理。  
  
到这里，就实现了最基本的“幻化式”换衣。关于训练脸部、鞋子等问题，考虑在下一节讨论。  
  

− 原理 ...

  
多个Lora同时生效时，图片必须满足：与每一个Lora的特征值都“足够”相似，具体有多相似，由权重决定。权重的具体数字不重要，重要的是相对。  
  
假设有Lora A 和B 现在我要求图片在与A至少有0.5相似的前提下，同时与B 有0.4相似，这就很难了，往往会出现各种问题。这也就是为什么要强调用最少的权重来完成任务。  
  
假设Lora A 仅有头部的信息，那么我们约定Lora A 至少有0.5相似时，头部会按照与Lora A 内建的头部元素接近到“0.5”的程度来描绘。同时B代表身体，要求有0.4相似，但由于整幅图都是用扩散模型随机加噪声形成的，在下一次迭代中，A对整个图的影响，可能会导致更难完成“与B有0.4相似”的要求。  
  
而如果你发现与B相差很远，而提升与B相似度的要求，又会导致无法满足“与A 0.5相似”的要求。这就是扩散模型机制决定的局限性，除非使用局部重绘，但局部重绘也有一些其他问题，比如说衔接问题。  
  
所以使用多个Lora 最后都要找出一个最佳的平衡点，与A，B，C的相似度分别达到最大，而对其他的相似度影响达到最小。  
  
上面图中权重不够时，衣服颜色都未显示也是这个原因。当权重要求足够低，那么即使颜色不一致，也会被认为“足够相似”了。  

  
  
7，面部模型和其他模型的制作等  
  
面部模型的制作  

− 面部模型的制作 ...

[[https://bbs.nga.cn/read.php?tid=35865472](https://bbs.nga.cn/read.php?tid=35865472)]

  
  
其他模型的制作  
  
下面以制作一个鞋子的模型为例，来说明如何制作一个其他模型。  
  
注意模型越多，互相冲突越严重，实际上不能同时用太多(比如超过3个)lora的。  
  

− 其他模型的制作 ...

实例  
  
先尝试生成一个鞋子的模型，目标是使该鞋子可以和另一个衣服的Lora同时生效。  
  
首先一样选择素材。  
  
![](https://img.nga.178.com/attachments/mon_202303/26/-9lddQd6qe-lfkaZeT3cSsg-c6.jpg)  
  
我故意选择了一些全身或者半身的，而不是脚部特写。这是因为如果只有特写，机器很可能会把这鞋子随便乱画，起不到效果。当然了，也并不是非要reg，非reg的条件下，也有概率能够正确放置，只不过需要更多次数的尝试和修复，降低了效率罢了。  
  
接下来处理素材，同样把人物(包括鞋)分别处理成 512：768的比例。  
  
![](https://img.nga.178.com/attachments/mon_202303/26/-9lddQd6qh-fs25ZbT3cSsg-kk.jpg)  
  
人物放置在reg  
  
![](https://img.nga.178.com/attachments/mon_202303/26/-9lddQd6qg-j3j4K2rT3cSsg-lr.jpg)  
  
需要训练的鞋子放在 X_myshoes  
  
下面一步关键！  
  
  
虽然图片都是512：768的，但显然鞋子的尺寸要小于512，768，如果处理的时候处理成512，768会造成图片被拉伸，等同于降低了像素。  
  
此时把鞋子处理成 256，384的就可以了。全身仍然是512，768. (只要比例一致即可，不要求尺寸一致，这两个值比例都是2：3)  
  
![](https://img.nga.178.com/attachments/mon_202303/26/-9lddQd6qg-4i75ZcT3cSrm-p6.jpg)  
  
打标的时候发现，只有鞋子的话，标记很混乱，基本上是错的或者很难描述清楚，所以一定要加一个自己的tag(例如myshoes)，一会方便调用它。  
  
然后开始训练，我设置的是16次，epoch 10 batch 2 (batch 1 可能会更好点，因为这个图片小，所以可以batch 2)  
  
训练出模型，假设叫做 myshoes.safetensor ， 专属tag是 myshoes。  
  

  
  
  
8，使用XYZ图表应用多个lora出图  
  
下面以上面训练的两个Lora为例，让这个裙子和鞋子搭配起来。  
  
要用到XYZ表格进行精细调整，逐步逼近最优解。  
  
先声明一下，多个Lora，大量关键词的情况下，生成的每一次图片所要求的最优权重组合都不一样。而且有的图片构图怎么也不可能调优，所以不要试图一步到位，不存在什么一步到位、万能的组合或者万能的prompt、参数。  
  

− 实例，同时应用服装和鞋子 ...

  
下面应用3个Lora  
  
1个面部 Lora，占据Addnet 1 位置 初始Weight 0.68  
  
1个服装Lora，上面训练的， tag: testdress 占据Addnet 2 位置 初始 Weight 0.4  
  
1个服装Lora，上面训练的鞋子， tag: myshoes 占据 Addnet 3 位置 初始 Weight 0.4  
  
初始prompt：(为了示例，使用了最少的关键词)  
  
1girl, best quality, masterpiece, ultra high res, (photorealistic:1.4), solo, full body, standing, bangs, looking at viewer, pink dress, testdress, myshoes  
  
CFG 7.5 768,1024 竖版分辨率， Step 30步，DPM SDE KAR 方法  
  
其实我这个有点苛刻了，非要出全身大图，如果是半身或者坐姿，可能会好很多，但是作为示例，肯定要按照比较难的来。  
  
解释一下，后面三个关键词可以不加。pink dress 的意思是在裙子的Lora权重较低的情况下可能颜色会丢失或者错误，通过限制颜色，可以在不增加权重的前提下更容易达到效果。但是也有些副作用，下面会说。  
  
最后两个关键词是指定要调用两个Lora的内容。因为如果有些lora(比如鞋子)权重比较低，出图可能会直接被忽略，会出没有脚的图。一定要求它调用的话能提高成功率。但是也会有一些副作用，下面说。  
  
任何prompt都是互相作用的，都是这个提升了，那个就会降低，不存在没有副作用的设置。一切靠你慢慢调整。  
  
  
第一步：先随机生成一批图  
  
  
因为对于每个随机批次而言，每一次，每个prompt、Lora的效果都有不确定性，很多图根本无法调整，一开始就是错的，必须先大量出图，找出那些潜在的，可能修好的图。  
  
![](https://img.nga.178.com/attachments/mon_202303/26/-9lddQd6qf-cv4uZiT3cStc-ov.jpg)  
  
出了几版后，这四张里面，第一张肯定没戏，第三张多了个脚，估计难度也大，看第四张构图是完整的(包括衣服和鞋子)，那么记录下来第四张的随机种子(比如1296893022)，以第四张为蓝本生图。  
  
第二步，XYZ寻找合适组合  
  
  
因为有3个Lora，我们假定面部先不变，那么变量就是两个 Addnet 2 Weight 和 Addnet 3 Weight。分别是衣服和鞋子的权重。  
  
每个权重设置3组变量，一次生成9张  
  
  
![](https://img.nga.178.com/attachments/mon_202303/26/-9lddQpkyh-2kv9Z10T3cSpl-sg.jpg)  
  
可以看到，随着衣服权重的增大(横轴，ADD NET 2)手部出现错误的概率增大，但是衣服本身细节提升有限。  
  
随着鞋子权重的增大(纵轴，ADD NET 3) 变化似乎不明显。但是鞋子的颜色也变成了粉色，未正确表现出本身的颜色(白色)。  
  
如果你要求不高，就可以从中选一张收工了。或者是再出一版，把衣服的权重调小一些试试。  
  
但是我要求一定要完全同时表现出衣服和鞋子的细节来，怎么办？  
  
有几个方案，一个是通过prompt强行修正鞋子的颜色，后面加一个 white shoes 实测可行。但是这样会造成副作用就是手部的畸形，试了几次后都不太理想。  
  
另一个办法就是继续增加鞋子Lora的权重。但是增加权重会导致衣服Lora的权重相对降低(权重都是相对的)，所以也要适当提升衣服Lora的权重。  
  
重新再出一版：  
  
  
![](https://img.nga.178.com/attachments/mon_202303/26/-9lddQ8sg5-6xmmZzT3cSpj-sg.jpg)，  
会发现衣服权重提升后手崩得更厉害了，经过挑选，似乎左下角一张最接近衣服和鞋子最大还原。这张衣服是0.4，鞋子0.49.  
  
记住参数，关掉XYZ重新回到主页面再出图，同时试试衣服0.49， 0.50，的组合。  
  
  
第三步，调节面部和CFG SCALE  
  
下面我们已经有了这张图，它衣服的权重是0.4，鞋子的权重是0.5，但是面部有些问题，可能和我们的人物不是很像。同时分辨率也很低(这个问题，后面再说)  
  
![](https://img.nga.178.com/attachments/mon_202303/26/-9lddQ8sg5-iusuZoT3cSlh-sg.jpg)  
  
这时候既然服装的权重已经确定，就只剩下面部的权重，再开一版XYZ图，这次针对面部的权重进行微调。比如从0.65到0.7之间，每0.01出一张  
  
同时可以调节CFG，CFG代表AI对你prompt的响应度，CFG越高响应就越高，但是细节会有损失。  
  
经过调节，发现人物lora权重在0.65，CFG 8 时，效果可以接受，手部细节也损失不多：  
  
![](https://img.nga.178.com/attachments/mon_202303/26/-9lddQ8sg5-zxbZtT3cSlc-sg.jpg)  
  
当然，手部细节如果还要求高，就要用到control net了，那是另一个话题了。  
  
  
第四步，修正分辨率  
  
你会发现这张图什么都好，就是分辨率低。  
  
上面我发了一张半身的图，没做任何修正，分辨率就不错了，但是全身的不行。因为全身768,1024的分辨率远高于训练的512，768。  
  
有几个办法，一个是降低图片尺寸，比如降低到600,800 会好一些。要么就是用工具拉高。但是不要用“高清重绘”，因为高清重绘等于是重新生成随机值了，你刚才找出来的最优解就无效了。  
  
要么就是用 ESRGAN-4X进行放大。  
  
这是ESRGAN-4X放大后的图像，基本上符合我们的要求了。  
  
![](https://img.nga.178.com/attachments/mon_202303/26/-9lddQd9uo-56okZpT3cSlc-sg.jpg)  
  
  
  
总结：多个Lora可以同时使用，甚至可以多人、多脸、多衣。 主要是在多个lora同时起作用时，“权重”是相对的，一个权重增加了，等同于另一个权重的减少。  
  
对于每一个随机批次，最佳组合都不一样，要挑选好的构图进行微调。  
  
对于全身大图，我们的素材可能不合格，要么改变姿势(比如取个半身或者坐姿)，要么就只能接受较低的分辨率了。  
  
  
9，参见  
  
[[https://bbs.nga.cn/read.php?tid=35850123](https://bbs.nga.cn/read.php?tid=35850123)]  
  
和上文的用机器打tag有冲突。  
  
  
10,control net 出高清大图解决脸崩  
  
[[https://bbs.nga.cn/read.php?tid=35918258](https://bbs.nga.cn/read.php?tid=35918258)]

  
  
https://bbs.nga.cn/read.php?&tid=35774713